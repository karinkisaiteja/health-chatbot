{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ALNNaUMxlf7"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "import json\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qf4WenJ5xvF8"
      },
      "outputs": [],
      "source": [
        "words=[]\n",
        "classes = []\n",
        "documents = []\n",
        "ignore_words = ['?', '!']\n",
        "data_file = open('intents1.json').read()\n",
        "intents = json.loads(data_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-95zEL7Uxxe5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffaeec23-463c-4635-8175-f517e70a118f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7Wwd0KAxz9w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "928dd509-3097-4638-e28b-ff5d7b8bc5c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIF2TmQUx20N"
      },
      "outputs": [],
      "source": [
        "for intent in intents['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "\n",
        "        #tokenize each word\n",
        "        w = nltk.word_tokenize(pattern)\n",
        "        words.extend(w)\n",
        "        #add documents in the corpus\n",
        "        documents.append((w, intent['tag']))\n",
        "\n",
        "        # add to our classes list\n",
        "        if intent['tag'] not in classes:\n",
        "            classes.append(intent['tag'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "an2wQKWSx5gQ",
        "outputId": "132f24c4-584c-4de7-ac32-6eff5d137b93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "616 documents\n",
            "44 classes ['Causes of heart disease', 'Effect of diet on heart disease', 'Effect of medical condition of patient on heart disease', 'Effect of physical activity on heart diease', 'Error', 'Heart Disease', 'Impact of exercise on heart disease', 'Impact of heart disease', 'Response not correct', 'Role of Age in heart disease', 'Role of Smoking in heart disease', 'Role of blood pressure in heart disease', 'Types of heart disease', 'appointment with heart specialist', 'causes of diabetes', 'causes of pneumonia', 'chest pain related to heart disease', 'diagnosis of heart disease', 'effect of cholesterol on heart disease', 'effect of fasting blood sugar on heart disease', 'emergency situations in heart disease', 'factors inducing heart disease', 'greeting', 'health_risks_obesity', 'heart rate', 'importance of exercise for diabetes', 'introduction', 'introduction to diabetes', 'introduction to pneumonia', 'medications for heart disease', 'monitoring of heart health', 'personal', 'prevention from heart disease', 'prevention measures for diabetes', 'prevention measures for pneumonia', 'risk factors of pneumonia', 'role of Genetics in heart disease', 'symptoms of diabetes', 'symptoms of heart disease', 'symptoms of pneumonia', 'terms of heart disease', 'treatment of diabetes', 'treatments for pneumonia', 'user response']\n",
            "681 unique lemmatized words ['$', '%', '&', \"'\", \"'m\", \"'s\", \"'silent\", '(', ')', '*', ',', '.', '1', '123', '2', '@', '^', 'a', 'abnormal', 'about', 'access', 'accompanying', 'across', 'action', 'activity', 'adherence', 'adult', 'advantage', 'advice', 'aeds', 'aerobic', 'affect', 'affected', 'after', 'against', 'age', 'age-related', 'age-specific', 'aid', 'alcohol', 'all', 'alleviate', 'alternative', 'always', 'am', 'ambiguous', 'an', 'and', 'angina', 'angiogram', 'antibiotic', 'antiplatelet', 'antiviral', 'anxiety', 'any', 'anyone', 'appointment', 'apps', 'are', 'arise', 'arrest', 'arrhythmia', 'artery', 'ask', 'aspiration', 'ass', 'assist', 'assistance', 'associated', 'asymptomatic', 'at', 'atherosclerosis', 'atrial', 'attack', 'attention', 'automated', 'available', 'avoid', 'avoiding', 'aware', 'bacteria', 'bacterial', 'balanced', 'basic', 'be', 'become', 'before', 'beneficial', 'benefit', 'beta-blockers', 'better', 'between', 'bit', 'blood', 'body', 'booking', 'breath', 'breathing', 'by', 'cad', 'caffeine', 'call', 'can', 'cancel', 'cardiac', 'cardiologist', 'cardiology', 'cardiomyopathy', 'cardiovascular', 'care', 'caregiver', 'case', 'cause', 'caused', 'ceasing', 'certain', 'cessation', 'change', 'chd', 'check', 'check-up', 'check-ups', 'checked', 'chest', 'chf', 'child', 'cholesterol', 'chronic', 'classified', 'common', 'commonly', 'communicate', 'community', 'compare', 'compared', 'complementary', 'complication', 'component', 'concern', 'concerned', 'condition', 'confusion', 'congestive', 'connection', 'considered', 'consistently', 'consult', 'consultation', 'consume', 'consumption', 'context', 'contribute', 'contributor', 'control', 'controlling', 'coronary', 'correct', 'correlation', 'coughing', 'could', 'counseling', 'cpr', 'cure', 'cured', 'cvd', 'daily', 'day', 'decline', 'defibrillator', 'define', 'describe', 'detect', 'determine', 'determining', 'develop', 'developing', 'development', 'device', 'diabetes', 'diagnose', 'diagnosed', 'diagnosis', 'diagnostic', 'diet', 'dietary', 'differ', 'difference', 'different', 'differentiate', 'disease', 'distinguish', 'dizziness', 'do', 'doctor', 'doe', 'doing', 'drug', 'duration', 'during', 'early', 'eating', 'echocardiography', 'effect', 'effective', 'effectively', 'elevated', 'emergency', 'endocarditis', 'energy', 'environmental', 'ethnicity', 'even', 'event', 'exercise', 'exercising', 'expected', 'experience', 'experiencing', 'explain', 'exposed', 'exposure', 'extent', 'external', 'factor', 'failure', 'fainting', 'family', 'fasting', 'fatigue', 'fever', 'fibrillation', 'financial', 'find', 'first', 'fitness', 'flu', 'fluctuate', 'follow-up', 'food', 'for', 'former', 'forum', 'frequency', 'frequent', 'from', 'function', 'fungal', 'funny', 'gastrointestinal', 'gender', 'gender-specific', 'gene', 'general', 'genetic', 'genetics', 'gestational', 'get', 'giving', 'glucose', 'good', 'gradual', 'group', 'guidance', 'habit', 'hand', 'handling', 'have', 'having', 'hdl', 'health', 'healthcare', 'healthy', 'heart', 'heart-healthy', 'heart-related', 'hello', 'help', 'helplines', 'hereditary', 'hey', 'hi', 'high', 'high-density', 'higher', 'history', 'home', 'hormone', 'hospitalization', 'hospitalized', 'how', 'hsfdgshfhgsafdhgsfd', 'hygiene', 'hypertension', 'i', 'identify', 'identifying', 'if', 'ignoring', 'ihd', 'illness', 'im', 'imaging', 'immediate', 'immediately', 'immune', 'immunity', 'impact', 'implication', 'importance', 'important', 'improve', 'improving', 'in', 'inaccurate', 'inactivity', 'incidence', 'increase', 'increased', 'indicate', 'indicator', 'indigestion', 'individual', 'infarction', 'infection', 'inflammation', 'influence', 'information', 'inherited', 'initial', 'injection', 'instruction', 'insulin', 'intake', 'interact', 'interested', 'into', 'involve', 'is', 'ischemic', 'issue', 'it', 'joke', 'journal', 'keeping', 'killer', 'know', 'known', 'lack', 'last', 'latest', 'ldl', 'lead', 'leading', 'level', 'life', 'lifestyle', 'like', 'likelihood', 'lingering', 'link', 'linking', 'lipoprotein', 'list', 'long', 'long-term', 'look', 'loss', 'low', 'low-density', 'lower', 'lowering', 'main', 'maintain', 'maintaining', 'make', 'manage', 'managed', 'management', 'managing', 'maximum', 'may', 'me', 'meaning', 'measure', 'measured', 'measuring', 'medical', 'medication', 'mediterranean', 'member', 'men', 'mental', 'method', 'mitral', 'moderation', 'monitor', 'monitored', 'monitoring', 'more', 'most', 'much', 'murmur', 'music', 'mutation', 'my', 'myocardial', 'myth', \"n't\", 'name', 'natural', 'nausea', 'necessary', 'need', 'needed', 'negatively', 'never', 'new', 'news', 'non-cardiac', 'normal', 'not', 'nutrition', 'obesity', 'obtain', 'occupation', 'occur', 'of', 'often', 'okay', 'older', 'on', 'one', 'online', 'opinion', 'optimal', 'option', 'or', 'oral', 'other', 'out', 'over', 'over-the-counter', 'overall', 'oxygen', 'pain', 'pancreatitis', 'panic', 'parameter', 'pathogen', 'patient', 'pattern', 'pectoris', 'pericarditis', 'peripheral', 'person', 'physical', 'physician', 'plan', 'platform', 'play', 'please', 'pneumonia', 'pollutant', 'population', 'portion', 'positive', 'possible', 'potential', 'practice', 'practitioner', 'pre-existing', 'precaution', 'prediabetes', 'predispose', 'predisposition', 'pregnancy', 'preparation', 'prepare', 'prescribe', 'prescribed', 'presence', 'pressure', 'prevent', 'prevented', 'preventing', 'prevention', 'preventive', 'primary', 'probability', 'problem', 'procedure', 'process', 'processed', 'professional', 'program', 'prolapse', 'promote', 'prompt', 'prone', 'pronounced', 'proper', 'provide', 'provider', 'pulse', 'question', 'quick', 'quitting', 'range', 'rate', 'reading', 'reason', 'recognize', 'recommendation', 'recommended', 'record', 'recover', 'recovering', 'recovery', 'recurring', 'reduce', 'reducing', 'reduction', 'referral', 'regular', 'regularly', 'regulating', 'relate', 'related', 'relationship', 'reliable', 'reliance', 'relieve', 'remedy', 'remotely', 'require', 'reschedule', 'resistance', 'respiratory', 'response', 'rest', 'resting', 'result', 'reversed', 'risk', 'role', 'routine', 'safe', 'schedule', 'screening', 'season', 'seasonal', 'second', 'seek', 'self-monitoring', 'sensitivity', 'serious', 'service', 'severity', 'shortness', 'should', 'side', 'sign', 'significance', 'significant', 'silent', 'similar', 'simple', 'skin', 'sleep', 'smoked', 'smoker', 'smoking', 'some', 'someone', 'something', 'specialist', 'specific', 'stabilize', 'statin', 'status', 'stenosis', 'step', 'still', 'strategy', 'strength', 'strengthen', 'stress', 'stroke', 'sudden', 'sugar', 'supplement', 'support', 'susceptibility', 'susceptible', 'suspected', 'symptom', 'system', 'tachycardia', 'take', 'taken', 'target', 'telemedicine', 'tell', 'term', 'test', 'testing', 'than', 'that', 'the', 'their', 'therapy', 'there', 'they', 'think', 'thinner', 'thirst', 'this', 'those', 'through', 'throughout', 'time', 'to', 'today', 'too', 'tool', 'tracking', 'training', 'trait', 'transmitted', 'treat', 'treated', 'treating', 'treatment', 'type', 'typical', 'typically', 'unexplained', 'up', 'upon', 'urination', 'use', 'used', 'usually', 'utilized', 'vaccinated', 'vaccination', 'vaccine', 'valve', 'valvular', 'variation', 'vary', 'ventilator-associated', 'ventricular', 'viable', 'viral', 'virtual', 'virus', 'vision', 'vital', 'vomiting', 'wa', 'waiting', 'walking', 'warning', 'way', 'weakened', 'weakness', 'wearable', 'weather', 'weight', 'what', 'when', 'while', 'who', 'why', 'with', 'woman', 'worsen', 'wrong', 'you', 'your']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# lemmatize, lower each word and remove duplicates\n",
        "words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words]\n",
        "words = sorted(list(set(words)))\n",
        "# sort classes\n",
        "classes = sorted(list(set(classes)))\n",
        "# documents = combination between patterns and intents\n",
        "print (len(documents), \"documents\")\n",
        "# classes = intents\n",
        "print (len(classes), \"classes\", classes)\n",
        "# words = all words, vocabulary\n",
        "print (len(words), \"unique lemmatized words\", words)\n",
        "\n",
        "pickle.dump(words,open('words.pkl','wb'))\n",
        "pickle.dump(classes,open('classes.pkl','wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUOAgKO5x76C",
        "outputId": "64bd6df1-1723-47cc-ab0b-3de12e1c157a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data created\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# create our training data\n",
        "training = []\n",
        "\n",
        "# create an empty array for our output\n",
        "output_empty = [0] * len(classes)\n",
        "\n",
        "# training set, bag of words for each sentence\n",
        "for doc in documents:\n",
        "    # initialize our bag of words\n",
        "    bag = []\n",
        "    # list of tokenized words for the pattern\n",
        "    pattern_words = doc[0]\n",
        "    # lemmatize each word - create base word, in an attempt to represent related words\n",
        "    pattern_words = [lemmatizer.lemmatize(word.lower()) for word in pattern_words]\n",
        "    # create our bag of words array with 1, if word match found in the current pattern\n",
        "    for w in words:\n",
        "        bag.append(1) if w in pattern_words else bag.append(0)\n",
        "\n",
        "    # output is '0' for each tag and '1' for the current tag (for each pattern)\n",
        "    output_row = list(output_empty)\n",
        "    output_row[classes.index(doc[1])] = 1\n",
        "\n",
        "    training.append([bag, output_row])\n",
        "\n",
        "# shuffle our features\n",
        "random.shuffle(training)\n",
        "\n",
        "# Extract features and labels from the training list\n",
        "features = [x[0] for x in training]\n",
        "labels = [x[1] for x in training]\n",
        "\n",
        "# Pad sequences to make them uniform in length\n",
        "max_length = max(len(seq) for seq in features)\n",
        "padded_features = pad_sequences(features, maxlen=max_length, padding='post')\n",
        "\n",
        "# Convert features and labels to NumPy arrays\n",
        "train_x = np.array(padded_features)\n",
        "train_y = np.array(labels)\n",
        "\n",
        "print(\"Training data created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ksoo1uvByAAK",
        "outputId": "62cd0299-5ea6-49c2-e46a-d1b3af537231"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "124/124 [==============================] - 1s 3ms/step - loss: 3.7828 - accuracy: 0.0325\n",
            "Epoch 2/100\n",
            "124/124 [==============================] - 0s 2ms/step - loss: 3.7249 - accuracy: 0.0649\n",
            "Epoch 3/100\n",
            "124/124 [==============================] - 0s 2ms/step - loss: 3.6436 - accuracy: 0.0779\n",
            "Epoch 4/100\n",
            "124/124 [==============================] - 0s 2ms/step - loss: 3.5540 - accuracy: 0.0860\n",
            "Epoch 5/100\n",
            "124/124 [==============================] - 0s 2ms/step - loss: 3.4893 - accuracy: 0.0909\n",
            "Epoch 6/100\n",
            "124/124 [==============================] - 0s 2ms/step - loss: 3.4206 - accuracy: 0.0990\n",
            "Epoch 7/100\n",
            "124/124 [==============================] - 0s 2ms/step - loss: 3.2858 - accuracy: 0.1282\n",
            "Epoch 8/100\n",
            "124/124 [==============================] - 0s 2ms/step - loss: 3.1814 - accuracy: 0.1834\n",
            "Epoch 9/100\n",
            "124/124 [==============================] - 0s 2ms/step - loss: 3.0990 - accuracy: 0.1672\n",
            "Epoch 10/100\n",
            "124/124 [==============================] - 0s 2ms/step - loss: 2.9404 - accuracy: 0.2208\n",
            "Epoch 11/100\n",
            "124/124 [==============================] - 0s 2ms/step - loss: 2.7952 - accuracy: 0.2581\n",
            "Epoch 12/100\n",
            "124/124 [==============================] - 0s 2ms/step - loss: 2.7184 - accuracy: 0.2484\n",
            "Epoch 13/100\n",
            "124/124 [==============================] - 0s 3ms/step - loss: 2.5867 - accuracy: 0.3003\n",
            "Epoch 14/100\n",
            "124/124 [==============================] - 0s 3ms/step - loss: 2.5511 - accuracy: 0.2890\n",
            "Epoch 15/100\n",
            "124/124 [==============================] - 0s 4ms/step - loss: 2.3900 - accuracy: 0.3247\n",
            "Epoch 16/100\n",
            "124/124 [==============================] - 0s 3ms/step - loss: 2.3060 - accuracy: 0.3506\n",
            "Epoch 17/100\n",
            "124/124 [==============================] - 1s 4ms/step - loss: 2.2810 - accuracy: 0.3377\n",
            "Epoch 18/100\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 2.2318 - accuracy: 0.3620\n",
            "Epoch 19/100\n",
            "124/124 [==============================] - 0s 3ms/step - loss: 2.1342 - accuracy: 0.3977\n",
            "Epoch 20/100\n",
            "124/124 [==============================] - 0s 2ms/step - loss: 2.1040 - accuracy: 0.4058\n",
            "Epoch 21/100\n",
            "124/124 [==============================] - 0s 2ms/step - loss: 2.0545 - accuracy: 0.3945\n",
            "Epoch 22/100\n",
            "124/124 [==============================] - 0s 2ms/step - loss: 1.9811 - accuracy: 0.4448\n",
            "Epoch 23/100\n",
            "124/124 [==============================] - 0s 2ms/step - loss: 1.9614 - accuracy: 0.4286\n",
            "Epoch 24/100\n",
            "124/124 [==============================] - 0s 3ms/step - loss: 1.8612 - accuracy: 0.4545\n",
            "Epoch 25/100\n",
            "124/124 [==============================] - 1s 4ms/step - loss: 1.8156 - accuracy: 0.4529\n",
            "Epoch 26/100\n",
            "124/124 [==============================] - 0s 4ms/step - loss: 1.7640 - accuracy: 0.4805\n",
            "Epoch 27/100\n",
            "124/124 [==============================] - 0s 4ms/step - loss: 1.7935 - accuracy: 0.4627\n",
            "Epoch 28/100\n",
            "124/124 [==============================] - 0s 4ms/step - loss: 1.6595 - accuracy: 0.4919\n",
            "Epoch 29/100\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 1.6094 - accuracy: 0.5162\n",
            "Epoch 30/100\n",
            "124/124 [==============================] - 0s 4ms/step - loss: 1.6101 - accuracy: 0.5195\n",
            "Epoch 31/100\n",
            "124/124 [==============================] - 0s 4ms/step - loss: 1.5524 - accuracy: 0.5519\n",
            "Epoch 32/100\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 1.5552 - accuracy: 0.5471\n",
            "Epoch 33/100\n",
            "124/124 [==============================] - 1s 4ms/step - loss: 1.4689 - accuracy: 0.5795\n",
            "Epoch 34/100\n",
            "124/124 [==============================] - 0s 4ms/step - loss: 1.4500 - accuracy: 0.5698\n",
            "Epoch 35/100\n",
            "124/124 [==============================] - 1s 4ms/step - loss: 1.3599 - accuracy: 0.5942\n",
            "Epoch 36/100\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 1.3588 - accuracy: 0.5812\n",
            "Epoch 37/100\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 1.3452 - accuracy: 0.5860\n",
            "Epoch 38/100\n",
            "124/124 [==============================] - 0s 4ms/step - loss: 1.3469 - accuracy: 0.5925\n",
            "Epoch 39/100\n",
            "124/124 [==============================] - 0s 3ms/step - loss: 1.3480 - accuracy: 0.5974\n",
            "Epoch 40/100\n",
            "124/124 [==============================] - 0s 3ms/step - loss: 1.3008 - accuracy: 0.6006\n",
            "Epoch 41/100\n",
            "124/124 [==============================] - 0s 3ms/step - loss: 1.2196 - accuracy: 0.6510\n",
            "Epoch 42/100\n",
            "124/124 [==============================] - 0s 3ms/step - loss: 1.2553 - accuracy: 0.6201\n",
            "Epoch 43/100\n",
            "124/124 [==============================] - 1s 4ms/step - loss: 1.1978 - accuracy: 0.6461\n",
            "Epoch 44/100\n",
            "124/124 [==============================] - 1s 4ms/step - loss: 1.2188 - accuracy: 0.6347\n",
            "Epoch 45/100\n",
            "124/124 [==============================] - 0s 4ms/step - loss: 1.1045 - accuracy: 0.6867\n",
            "Epoch 46/100\n",
            "124/124 [==============================] - 0s 3ms/step - loss: 1.1512 - accuracy: 0.6477\n",
            "Epoch 47/100\n",
            "124/124 [==============================] - 0s 2ms/step - loss: 1.1409 - accuracy: 0.6753\n",
            "Epoch 48/100\n",
            "124/124 [==============================] - 0s 2ms/step - loss: 1.0587 - accuracy: 0.6753\n",
            "Epoch 49/100\n",
            "124/124 [==============================] - 0s 2ms/step - loss: 1.0587 - accuracy: 0.6802\n",
            "Epoch 50/100\n",
            "124/124 [==============================] - 0s 2ms/step - loss: 0.9683 - accuracy: 0.7110\n",
            "Epoch 51/100\n",
            "124/124 [==============================] - 0s 3ms/step - loss: 1.0214 - accuracy: 0.6867\n",
            "Epoch 52/100\n",
            "124/124 [==============================] - 0s 3ms/step - loss: 1.0024 - accuracy: 0.6916\n",
            "Epoch 53/100\n",
            "124/124 [==============================] - 0s 3ms/step - loss: 0.9922 - accuracy: 0.7321\n",
            "Epoch 54/100\n",
            "124/124 [==============================] - 0s 3ms/step - loss: 0.9422 - accuracy: 0.7192\n",
            "Epoch 55/100\n",
            "124/124 [==============================] - 0s 3ms/step - loss: 0.9580 - accuracy: 0.7078\n",
            "Epoch 56/100\n",
            "124/124 [==============================] - 0s 3ms/step - loss: 0.8962 - accuracy: 0.7386\n",
            "Epoch 57/100\n",
            "124/124 [==============================] - 0s 3ms/step - loss: 0.8765 - accuracy: 0.7321\n",
            "Epoch 58/100\n",
            "124/124 [==============================] - 0s 3ms/step - loss: 0.8985 - accuracy: 0.7240\n",
            "Epoch 59/100\n",
            "124/124 [==============================] - 0s 3ms/step - loss: 0.9187 - accuracy: 0.7289\n",
            "Epoch 60/100\n",
            "124/124 [==============================] - 0s 4ms/step - loss: 0.8994 - accuracy: 0.7240\n",
            "Epoch 61/100\n",
            "124/124 [==============================] - 0s 3ms/step - loss: 0.8931 - accuracy: 0.7500\n",
            "Epoch 62/100\n",
            "124/124 [==============================] - 0s 2ms/step - loss: 0.8375 - accuracy: 0.7451\n",
            "Epoch 63/100\n",
            "124/124 [==============================] - 0s 2ms/step - loss: 0.8460 - accuracy: 0.7549\n",
            "Epoch 64/100\n",
            "124/124 [==============================] - 0s 2ms/step - loss: 0.8072 - accuracy: 0.7646\n",
            "Epoch 65/100\n",
            "124/124 [==============================] - 0s 2ms/step - loss: 0.7332 - accuracy: 0.7825\n",
            "Epoch 66/100\n",
            "124/124 [==============================] - 0s 2ms/step - loss: 0.7970 - accuracy: 0.7679\n",
            "Epoch 67/100\n",
            "124/124 [==============================] - 0s 2ms/step - loss: 0.7660 - accuracy: 0.7857\n",
            "Epoch 68/100\n",
            "124/124 [==============================] - 0s 3ms/step - loss: 0.7479 - accuracy: 0.7825\n",
            "Epoch 69/100\n",
            "124/124 [==============================] - 0s 3ms/step - loss: 0.7119 - accuracy: 0.7744\n",
            "Epoch 70/100\n",
            "124/124 [==============================] - 0s 4ms/step - loss: 0.7191 - accuracy: 0.7630\n",
            "Epoch 71/100\n",
            "124/124 [==============================] - 0s 2ms/step - loss: 0.7049 - accuracy: 0.7922\n",
            "Epoch 72/100\n",
            "124/124 [==============================] - 0s 2ms/step - loss: 0.7168 - accuracy: 0.7597\n",
            "Epoch 73/100\n",
            "124/124 [==============================] - 0s 2ms/step - loss: 0.6555 - accuracy: 0.8133\n",
            "Epoch 74/100\n",
            "124/124 [==============================] - 0s 3ms/step - loss: 0.6605 - accuracy: 0.7971\n",
            "Epoch 75/100\n",
            "124/124 [==============================] - 0s 3ms/step - loss: 0.7041 - accuracy: 0.7825\n",
            "Epoch 76/100\n",
            "124/124 [==============================] - 1s 4ms/step - loss: 0.6688 - accuracy: 0.7987\n",
            "Epoch 77/100\n",
            "124/124 [==============================] - 0s 4ms/step - loss: 0.6102 - accuracy: 0.8084\n",
            "Epoch 78/100\n",
            "124/124 [==============================] - 0s 3ms/step - loss: 0.6383 - accuracy: 0.8117\n",
            "Epoch 79/100\n",
            "124/124 [==============================] - 0s 3ms/step - loss: 0.6412 - accuracy: 0.7971\n",
            "Epoch 80/100\n",
            "124/124 [==============================] - 0s 3ms/step - loss: 0.6117 - accuracy: 0.8036\n",
            "Epoch 81/100\n",
            "124/124 [==============================] - 0s 4ms/step - loss: 0.6018 - accuracy: 0.8231\n",
            "Epoch 82/100\n",
            "124/124 [==============================] - 0s 4ms/step - loss: 0.5800 - accuracy: 0.8393\n",
            "Epoch 83/100\n",
            "124/124 [==============================] - 0s 2ms/step - loss: 0.6173 - accuracy: 0.7987\n",
            "Epoch 84/100\n",
            "124/124 [==============================] - 0s 3ms/step - loss: 0.6028 - accuracy: 0.8182\n",
            "Epoch 85/100\n",
            "124/124 [==============================] - 0s 2ms/step - loss: 0.5816 - accuracy: 0.8328\n",
            "Epoch 86/100\n",
            "124/124 [==============================] - 0s 3ms/step - loss: 0.6124 - accuracy: 0.8247\n",
            "Epoch 87/100\n",
            "124/124 [==============================] - 0s 3ms/step - loss: 0.5912 - accuracy: 0.8149\n",
            "Epoch 88/100\n",
            "124/124 [==============================] - 0s 3ms/step - loss: 0.5144 - accuracy: 0.8506\n",
            "Epoch 89/100\n",
            "124/124 [==============================] - 0s 3ms/step - loss: 0.5361 - accuracy: 0.8344\n",
            "Epoch 90/100\n",
            "124/124 [==============================] - 0s 2ms/step - loss: 0.5408 - accuracy: 0.8474\n",
            "Epoch 91/100\n",
            "124/124 [==============================] - 0s 2ms/step - loss: 0.6189 - accuracy: 0.8036\n",
            "Epoch 92/100\n",
            "124/124 [==============================] - 0s 3ms/step - loss: 0.5227 - accuracy: 0.8474\n",
            "Epoch 93/100\n",
            "124/124 [==============================] - 0s 3ms/step - loss: 0.5516 - accuracy: 0.8279\n",
            "Epoch 94/100\n",
            "124/124 [==============================] - 0s 3ms/step - loss: 0.5350 - accuracy: 0.8344\n",
            "Epoch 95/100\n",
            "124/124 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.8669\n",
            "Epoch 96/100\n",
            "124/124 [==============================] - 0s 2ms/step - loss: 0.5193 - accuracy: 0.8377\n",
            "Epoch 97/100\n",
            "124/124 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.8214\n",
            "Epoch 98/100\n",
            "124/124 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.8474\n",
            "Epoch 99/100\n",
            "124/124 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.8474\n",
            "Epoch 100/100\n",
            "124/124 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.8588\n",
            "Model created\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Create model - 3 layers. First layer 128 neurons, second layer 64 neurons, and 3rd output layer contains the number of neurons equal to the number of intents to predict output intent with softmax\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(len(train_y[0]), activation='softmax'))\n",
        "\n",
        "# Compile model. Stochastic gradient descent with Nesterov accelerated gradient gives good results for this model\n",
        "sgd = SGD(learning_rate=0.002 , momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "# Fitting and saving the model\n",
        "hist = model.fit(np.array(train_x), np.array(train_y), epochs=100, batch_size=5, verbose=1)\n",
        "model.save('chatbot_model.h5', hist)\n",
        "\n",
        "print(\"Model created\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 897
        },
        "id": "K8c3eGn9yCu8",
        "outputId": "8a6e0e2a-a4a4-428f-bc89-a315061c45a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chatbot Testing Interface\n",
            "Type 'quit' to exit\n",
            "You: hi\n",
            "1/1 [==============================] - 0s 90ms/step\n",
            "Bot: Hi there! Welcome to Health Bot. How can I assist you today?\n",
            "You: what si diabeties\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Bot: Hi there, how can I help?\n",
            "You: what is diabeties\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Bot: Mitral valve prolapse is a condition where the valve between the left upper and lower chambers of the heart doesn't close properly.\n",
            "You: diabetes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Bot: While there is currently no cure for diabetes, effective management can help control blood sugar levels and prevent or delay complications.\n",
            "You: hmm\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Bot: I'm sorry, but I can only provide assistance with questions related to Heart Disease inquiries. If you have any questions about our services, please don't hesitate to ask, and I'll be glad to help!\n",
            "You: hello\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Bot: Hi there, how can I help?\n",
            "You: what is heart disease\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Bot: Heart disease refers to a range of conditions affecting the heart, including coronary artery disease, heart failure, and arrhythmias. It typically involves the gradual accumulation of plaque in the arteries, restricting blood flow and increasing the risk of heart attacks. Lifestyle factors, genetics, and underlying health conditions contribute to the development of heart disease, making it a leading cause of morbidity and mortality globally. Management often involves lifestyle modifications, medication, and, in severe cases, surgical interventions.\n",
            "You: bye\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Bot: I'm sorry, but I can only provide assistance with questions related to Heart Disease inquiries. If you have any questions about our services, please don't hesitate to ask, and I'll be glad to help!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-e2c1a0dc837c>\u001b[0m in \u001b[0;36m<cell line: 62>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'quit'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import json\n",
        "import pickle\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "\n",
        "model = load_model('chatbot_model.h5')\n",
        "words = pickle.load(open('words.pkl', 'rb'))\n",
        "classes = pickle.load(open('classes.pkl', 'rb'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def clean_up_sentence(sentence):\n",
        "    # Tokenize the user input and lemmatize each word\n",
        "    sentence_words = nltk.word_tokenize(sentence)\n",
        "    sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n",
        "    return sentence_words\n",
        "\n",
        "def bow(sentence, words, show_details=True):\n",
        "\n",
        "    sentence_words = clean_up_sentence(sentence)\n",
        "    bag = [0]*len(words)\n",
        "    for s in sentence_words:\n",
        "        for i, w in enumerate(words):\n",
        "            if w == s:\n",
        "                bag[i] = 1\n",
        "                if show_details:\n",
        "                    print(\"found in bag: %s\" % w)\n",
        "    return(np.array(bag))\n",
        "\n",
        "def predict_class(sentence, model):\n",
        "\n",
        "    p = bow(sentence, words, show_details=False)\n",
        "    res = model.predict(np.array([p]))[0]\n",
        "    ERROR_THRESHOLD = 0.25\n",
        "    results = [[i, r] for i, r in enumerate(res) if r > ERROR_THRESHOLD]\n",
        "\n",
        "    results.sort(key=lambda x: x[1], reverse=True)\n",
        "    return_list = []\n",
        "    for r in results:\n",
        "        return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n",
        "    return return_list\n",
        "\n",
        "def get_response(intents_list, intents_json):\n",
        "    tag = intents_list[0]['intent']\n",
        "    list_of_intents = intents_json['intents']\n",
        "    for i in list_of_intents:\n",
        "        if i['tag'] == tag:\n",
        "            result = random.choice(i['responses'])\n",
        "            break\n",
        "    return result\n",
        "\n",
        "\n",
        "print(\"Chatbot Testing Interface\")\n",
        "print(\"Type 'quit' to exit\")\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() == 'quit':\n",
        "        break\n",
        "\n",
        "\n",
        "    ints = predict_class(user_input, model)\n",
        "    res = get_response(ints, intents)\n",
        "    print(\"Bot:\", res)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asziYmhxyMCD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}